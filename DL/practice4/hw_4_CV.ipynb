{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "esjnEdCWvyfF"
   },
   "source": [
    "Напишите функцию get_normalize, которая будет принимать тензор с признаками объектов из какого-то датасета с картинками и будет возвращать поканальное среднее и поканальное стандартное отклонение. Гарантируется, что матрица будет иметь размер [N, C, H, W], где N это количество объектов, C — количество каналов, H, W — размеры изображений. Нужно вернуть кортеж из двух тензоров длины C.\n",
    "\n",
    "Ваша функция должна иметь следующую сигнатуру def get_normalize(features: torch.Tensor):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "H1uxPt7JvOfE"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def get_normalize(features: torch.Tensor):\n",
    "    \"\"\"\n",
    "    Вычисляет поканальное среднее и стандартное отклонение для тензора изображений.\n",
    "\n",
    "    Args:\n",
    "        features: Тензор размерности [N, C, H, W]\n",
    "\n",
    "    Returns:\n",
    "        Кортеж (mean, std) из двух тензоров длины C\n",
    "    \"\"\"\n",
    "    # Вычисляем среднее по измерениям N, H, W (оставляем C)\n",
    "    mean = torch.mean(features, dim=(0, 2, 3))\n",
    "\n",
    "    # Вычисляем стандартное отклонение по измерениям N, H, W (оставляем C)\n",
    "    std = torch.std(features, dim=(0, 2, 3), unbiased=True)\n",
    "\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P3T7DizokH4c"
   },
   "source": [
    "Напишите функцию get_augmentations, которая будет возвращать готовые аугментации для обучающей выборки и для тестовой выборки. Она должна иметь следующую сигнатуру: def get_augmentations(train: bool = True) -> T.Compose:.\n",
    "\n",
    "Примените следующие аугментации:\n",
    "\n",
    " Измените размер изображения, чтобы его размер был 224 на 224 пикселя (и для обучающей и для тестовой выборки).\n",
    " Примените какие-нибудь аугментации из тех, что мы изучили на занятии (только для обучающей).\n",
    " Преобразуйте картинку в тензор.\n",
    " Примените нормализацию для датасета CIFAR10\n",
    "Понятно, что изменение размера к 224 на 224 и нормализация для CIFAR10 вместе сочетаются плохо. Поэтому в дальнейшем, когда будете использовать эту функцию для получения аугментаций для вашего нового датасета, не забудьте поменять их на специфичные ему.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision\n",
      "  Using cached torchvision-0.24.0-cp313-cp313-macosx_12_0_arm64.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.13/site-packages (from torchvision) (2.1.3)\n",
      "Requirement already satisfied: torch==2.9.0 in /opt/anaconda3/lib/python3.13/site-packages (from torchvision) (2.9.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/anaconda3/lib/python3.13/site-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.13/site-packages (from torch==2.9.0->torchvision) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/anaconda3/lib/python3.13/site-packages (from torch==2.9.0->torchvision) (4.12.2)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.13/site-packages (from torch==2.9.0->torchvision) (72.1.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/anaconda3/lib/python3.13/site-packages (from torch==2.9.0->torchvision) (1.13.3)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /opt/anaconda3/lib/python3.13/site-packages (from torch==2.9.0->torchvision) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.13/site-packages (from torch==2.9.0->torchvision) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /opt/anaconda3/lib/python3.13/site-packages (from torch==2.9.0->torchvision) (2025.3.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.13/site-packages (from sympy>=1.13.3->torch==2.9.0->torchvision) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.13/site-packages (from jinja2->torch==2.9.0->torchvision) (3.0.2)\n",
      "Using cached torchvision-0.24.0-cp313-cp313-macosx_12_0_arm64.whl (1.9 MB)\n",
      "Installing collected packages: torchvision\n",
      "Successfully installed torchvision-0.24.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "b7YpvGzvvz1m"
   },
   "outputs": [],
   "source": [
    "import torchvision.transforms as T\n",
    "\n",
    "def get_augmentations(train: bool = True) -> T.Compose:\n",
    "    # Нормализация для CIFAR10 (предварительно вычисленные значения)\n",
    "    means = (0.49139968, 0.48215841, 0.44653091)\n",
    "    stds = (0.24703223, 0.24348513, 0.26158784)\n",
    "\n",
    "    if train:\n",
    "        # Аугментации для обучающей выборки\n",
    "        transforms = T.Compose([\n",
    "            T.Resize((32, 32)),           # Изменение размера до 224x224\n",
    "            T.RandomHorizontalFlip(p=0.5),  # Случайное горизонтальное отражение\n",
    "            T.RandomRotation(10),           # Случайный поворот на ±10 градусов\n",
    "            T.ToTensor(),                   # Преобразование в тензор\n",
    "            T.Normalize(mean=means, std=stds)  # Нормализация\n",
    "        ])\n",
    "    else:\n",
    "        # Аугментации для тестовой выборки (только базовые преобразования)\n",
    "        transforms = T.Compose([\n",
    "            T.Resize((32, 32)),         \n",
    "            T.ToTensor(),                   # Преобразование в тензор\n",
    "            T.Normalize(mean=means, std=stds)  # Нормализация\n",
    "        ])\n",
    "\n",
    "    return transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "foxbY0kto5MS"
   },
   "source": [
    "Напишите функцию predict. Она должна принимать на вход нейронную сеть, даталоадер и torch.device. Она должна иметь следующую сигнатуру: def predict(model: nn.Module, loader: DataLoader, device: torch.device):\n",
    "\n",
    "Внутри функции сделайте следующие шаги:\n",
    "\n",
    "Создайте пустой список для хранения предсказаний.\n",
    "Проитерируйтесь по даталоадеру.\n",
    "На каждой итерации сделайте forward pass для батча, посчитайте классы как аргмакс по выходу нейросети, по логитам, добавьте тензор с предсказаниями в список.\n",
    "Сделайте конкатенацию всех предсказаний и верните этот тензор длины N, по числу объектов в датасете.\n",
    "Ваша функция должна возвращать тензор с классами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "HkqORFHQvzyG"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def predict(model: nn.Module, loader: DataLoader, device: torch.device) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Предсказывает классы для всего датасета.\n",
    "\n",
    "    Args:\n",
    "        model: Нейронная сеть\n",
    "        loader: DataLoader с данными\n",
    "        device: Устройство для вычислений (cpu/cuda)\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Тензор с предсказанными классами длины N\n",
    "    \"\"\"\n",
    "    model.eval()  # Переводим модель в режим оценки\n",
    "    predictions = []  # Пустой список для хранения предсказаний\n",
    "\n",
    "    with torch.no_grad():  # Отключаем вычисление градиентов\n",
    "        for batch in loader:\n",
    "            # Если даталоадер возвращает (inputs, labels) или только inputs\n",
    "            if isinstance(batch, (list, tuple)):\n",
    "                inputs = batch[0]\n",
    "            else:\n",
    "                inputs = batch\n",
    "\n",
    "            # Перемещаем данные на устройство\n",
    "            inputs = inputs.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Вычисляем argmax по логитам (предсказываем классы)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            # Добавляем предсказания в список\n",
    "            predictions.append(predicted.cpu())  # Перемещаем на CPU для экономии памяти\n",
    "\n",
    "    # Конкатенируем все предсказания в один тензор\n",
    "    all_predictions = torch.cat(predictions, dim=0)\n",
    "\n",
    "    return all_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XZEpQo8ZrjSY"
   },
   "source": [
    "Обучите модель из двух сверточных слоев на датасете CIFAR10, добейтесь значения метрики Accuracy в 70% на тестовой выборке. Ограничения касаются только количества сверточных слоев в архитектуре модели, можно использовать любые клевые штуки, что мы прошли на занятии. Вам нужно сдать код с функцией, которая возвращает модель, назовите эту функцию create_simple_conv_cifar. Она не принимает аргументов и возвращает модель. Также сдайте предсказание для тестовой выборки датасета CIFAR10, воспользуйтесь функцией predict из предыдущего задания. Воспользуйтесь torch.save для записи тензора с результатом предсказания на диск."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BfGYcFUlsMwF",
    "outputId": "cebf5a9a-d0f3-4438-da43-34d25d56a1ae"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "train_dataset = CIFAR10('./data', train=True, transform=get_augmentations(True), download=True)\n",
    "valid_dataset = CIFAR10('./data', train=False, transform=get_augmentations(False), download=True)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=8, pin_memory=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=128, shuffle=False, num_workers=8, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "KiuKc19QsF28"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def create_simple_conv_cifar() -> nn.Module:\n",
    "    class SimpleConvModel(nn.Module):\n",
    "        def __init__(self, num_classes=10):\n",
    "            super(SimpleConvModel, self).__init__()\n",
    "\n",
    "            # Первый сверточный блок\n",
    "            self.conv1 = nn.Conv2d(3, 64, 3, padding=1)\n",
    "            self.bn1 = nn.BatchNorm2d(64)\n",
    "\n",
    "            # Второй сверточный блок  \n",
    "            self.conv2 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "            self.bn2 = nn.BatchNorm2d(128)\n",
    "\n",
    "            # Pooling слои\n",
    "            self.pool = nn.MaxPool2d(2, 2)\n",
    "            self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "            # Автоматический расчет размера для полносвязного слоя\n",
    "            # Для CIFAR10 (32x32): после 2 пулингов: 32->16->8\n",
    "            self.fc_input_size = 128 * 8 * 8  # 128 каналов * 8 * 8\n",
    "            self.fc1 = nn.Linear(self.fc_input_size, 256)\n",
    "            self.fc2 = nn.Linear(256, num_classes)\n",
    "\n",
    "        def forward(self, x):\n",
    "            # Первый блок: 32x32 -> 16x16\n",
    "            x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "            x = self.dropout(x)\n",
    "\n",
    "            # Второй блок: 16x16 -> 8x8\n",
    "            x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "            x = self.dropout(x)\n",
    "\n",
    "            # Выпрямление с автоматическим определением размера\n",
    "            x = x.view(x.size(0), -1)\n",
    "\n",
    "            # Проверка размера (для отладки)\n",
    "            if x.size(1) != self.fc_input_size:\n",
    "                raise ValueError(f\"Expected input size {self.fc_input_size}, but got {x.size(1)}. \"\n",
    "                               f\"Make sure input images are 32x32 (CIFAR10) and not resized to 224x224.\")\n",
    "\n",
    "            # Полносвязные слои\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = self.dropout(x)\n",
    "            x = self.fc2(x)\n",
    "\n",
    "            return x\n",
    "    \n",
    "    return SimpleConvModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "3L12rPi3sF0P"
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, test_loader, device, epochs=50):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.5)\n",
    "\n",
    "    train_losses = []\n",
    "    test_accuracies = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        # Валидация\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data, target in test_loader:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                outputs = model(data)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += target.size(0)\n",
    "                correct += (predicted == target).sum().item()\n",
    "\n",
    "        accuracy = 100 * correct / total\n",
    "        train_losses.append(running_loss / len(train_loader))\n",
    "        test_accuracies.append(accuracy)\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader):.4f}, '\n",
    "              f'Test Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "    return train_losses, test_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Paa9HD_MtCQC",
    "outputId": "436764fb-3764-4477-a5ee-af5dde3c9a22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created with 2,176,010 parameters\n"
     ]
    }
   ],
   "source": [
    "model = create_simple_conv_cifar()\n",
    "print(f\"Model created with {sum(p.numel() for p in model.parameters()):,} parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rAcSHxrvsFv9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 1.6951, Test Accuracy: 51.81%\n",
      "Epoch 2/20, Loss: 1.3797, Test Accuracy: 59.28%\n",
      "Epoch 3/20, Loss: 1.2742, Test Accuracy: 63.32%\n",
      "Epoch 4/20, Loss: 1.2251, Test Accuracy: 64.82%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_losses, test_accuracies = train_model(model, train_loader, valid_loader, device, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-O8A_8ZctH-5"
   },
   "outputs": [],
   "source": [
    "predictions = predict(model, valid_loader, device)\n",
    "\n",
    "torch.save(predictions, 'cifar10_predictions.pt')\n",
    "print(f\"Predictions saved with shape: {predictions.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишите функцию predict_tta. Она должна принимать на вход нейронную сеть, даталоадер, torch.device и количество итераций по даталоадеру. Она должна иметь следующую сигнатуру: def predict_tta(model: nn.Module, loader: DataLoader, device: torch.device, iterations: int = 2):.\n",
    "\n",
    "В этой функции мы применим технику Test Time Augmentation. Основная идея заключается в том, чтобы сделать для каждой картинки из тестовой выборки несколько аугментированных вариантов и сделать для них предсказания. Потом эти предсказания усреднить и использовать как обычно. В синтаксисе PyTorch это вырождается в создание тестового датасета со случайными аугментациями (либо как на обучающей выборке, либо чуть более слабыми). После этого нужно проитерироваться по созданному датасету несколько раз и усреднить ответы модели.\n",
    "\n",
    "Внутри функции сделайте следующие шаги:\n",
    "\n",
    "Запустите цикл по количеству итераций.\n",
    "Внутри цикла проитерируйтесь по даталоадеру.\n",
    "Запишите ответы (не классы, а сырые выходы нейросети) модели в один большой тензор размера [N, C], где C — число классов, а N — количество объектов в датасете (то есть мы должны иметь для каждого объекта вектор из выходов нейросети, логиты).\n",
    "Сделайте из этих тензоров один огромный тензор размера [N, C, iterations], усредните его по итерациям, чтобы его размер стал [N, C]\n",
    "Дальше предскажите классы для объектов по этому тензору как аргмакс, верните их из функции.\n",
    "Ваша функция должна возвращать тензор с классами. Не забудьте переводить модель в режим применения и навешивать декоратор для выключения подсчета градиентов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_tta(model: nn.Module, loader: DataLoader, device: torch.device, iterations: int = 2) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Предсказывает классы с использованием Test Time Augmentation.\n",
    "    \n",
    "    Args:\n",
    "        model: Нейронная сеть\n",
    "        loader: DataLoader с данными (должен иметь случайные аугментации)\n",
    "        device: Устройство для вычислений (cpu/cuda)\n",
    "        iterations: Количество итераций TTA\n",
    "        \n",
    "    Returns:\n",
    "        torch.Tensor: Тензор с предсказанными классами длины N\n",
    "    \"\"\"\n",
    "    model.eval()  # Переводим модель в режим оценки\n",
    "    \n",
    "    # Список для хранения всех предсказаний по итерациям\n",
    "    all_logits = []\n",
    "    \n",
    "    with torch.no_grad():  # Отключаем вычисление градиентов\n",
    "        for iteration in range(iterations):\n",
    "            print(f\"TTA Iteration {iteration + 1}/{iterations}\")\n",
    "            \n",
    "            iteration_logits = []\n",
    "            \n",
    "            for batch in loader:\n",
    "                # Обрабатываем разные форматы возврата даталоадера\n",
    "                if isinstance(batch, (list, tuple)):\n",
    "                    inputs = batch[0]\n",
    "                else:\n",
    "                    inputs = batch\n",
    "                \n",
    "                inputs = inputs.to(device)\n",
    "                outputs = model(inputs)  # Получаем логиты [batch_size, num_classes]\n",
    "                iteration_logits.append(outputs.cpu())\n",
    "            \n",
    "            # Конкатенируем все батчи в один тензор [N, C] для текущей итерации\n",
    "            iteration_tensor = torch.cat(iteration_logits, dim=0)\n",
    "            all_logits.append(iteration_tensor)\n",
    "    \n",
    "    # Собираем все итерации в один тензор [N, C, iterations]\n",
    "    all_logits_tensor = torch.stack(all_logits, dim=2)  # [N, C, iterations]\n",
    "    \n",
    "    # Усредняем по итерациям (dim=2) -> получаем [N, C]\n",
    "    averaged_logits = torch.mean(all_logits_tensor, dim=2)\n",
    "    \n",
    "    # Предсказываем классы как argmax по усредненным логитам\n",
    "    final_predictions = torch.argmax(averaged_logits, dim=1)\n",
    "    \n",
    "    return final_predictions"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
